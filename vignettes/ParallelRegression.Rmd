---
title: "Parallel Regression Package"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{ParallelRegression}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

# Usage

This R package exports one function: `ParLR`. This function is solely for exploration purposes and should not be used in a general setting. It does not have many of the benefits of `glm`, and can't handle non-numerical data.

Currently it accepts 4 arguments:

- X - A matrix of independent variables
- Y - Response vector of 1s and 0s
- ncores - how many cores to use in parallel
- comm - the communication protocol to use

There are 3 items returned:

- beta - the returned $\beta$ value
- niter - how many iterations each subproblem took to converge
- all_betas - all of the betas observed during convergence. Each 25 row section is a different thread/subproblem.

Here is an example, with simulated data:
```{r}
n <- 2000
X <- matrix(rnorm(n*2, mean = 0, sd = 0.05), ncol=2)
beta <- c(1,2)

prob <- 1 / (1 + exp(-X %*% beta))
y <- rbinom(n, 1, prob)

ParallelRegression::ParLR(X, y, 2, 1)
```
# Experiments

If you want to compare the runtime of the three avaiable communication options, run the code below.

```{r, eval=FALSE}
library(ParallelRegression)
library(data.table)
library(ggplot2)
library(ggthemes)

RunExperiment <- function(n, p, s, k){
  
  # generate data
  X <- matrix(rnorm(n*p, mean = 0, sd = 0.05), ncol=p)
  vars_to_use <- sample(1:p, s)
  beta <- matrix(10*runif(p), ncol=1)
  beta[-vars_to_use] <- 0
  
  prob <- 1 / (1 + exp(-X %*% beta))
  y <- rbinom(n, 1, prob)
  
  # reference calc
  time_vec <- NULL
  diff_vec <- NULL
  iter_vec <- NULL
  for(i in 1:3){
    glm_time <- system.time(glm_obj <- glm(y ~ X - 1, family="binomial"))
    glm_coeff <- glm_obj$coeff
    time_vec <- c(time_vec, glm_time[3])
    diff_vec <- c(diff_vec, norm(glm_coeff - glm_coeff, "2") / norm(beta, "2"))
    iter_vec <- c(iter_vec, 0)
  }
  
  # test each communication option
  comm_opts <- 0:3
  for(comm in comm_opts){
    for(i in 1:3){
      new_alg_time <- system.time(new_alg_obj <- ParLR(X, y, k, comm))
      new_alg_coeff <- new_alg_obj$beta 
      diff_vec <- c(diff_vec, norm(glm_coeff - new_alg_coeff, "2") / norm(beta, "2"))
      time_vec <- c(time_vec, new_alg_time[3])
      iter_vec <- c(iter_vec, max(new_alg_obj$niter))
    }
  }
  
  
  
  results <- data.table("n" = rep(n, 3*(1+length(comm_opts))),
                        "p" = rep(p, 3*(1+length(comm_opts))),
                        "s" = rep(s, 3*(1+length(comm_opts))),
                        "k" = rep(k, 3*(1+length(comm_opts))),
                        "comm" = rep(c("glm", comm_opts), each=3),
                        "diff" = diff_vec,
                        "time" = time_vec,
                        "iter" = iter_vec)
  return(results)
}

results <- list()
for(n in seq(100000, 1000000, by=50000))  {
  for(cores in c(1, 2, 4)){
    print(paste(n, cores))
    l <- RunExperiment(n, 200, 30, cores)
    print(l)
    results <- append(results, list(l))
  }
}

# summarize results
final_results <- rbindlist(results)
# ignore glm runs
plot_data <- final_results[comm %in% c(0,3) , .(error = mean(diff),
                                            time = median(time),
                                            iter = max(iter)), by=.(n, p, s, k, comm)]
ggplot(plot_data, aes(x = n,
                      y = time,
                      group = interaction(k, comm),
                      color = as.character(k),
                      linetype = comm)) +
  geom_line() +
  theme_clean() +
  scale_color_colorblind()
```
